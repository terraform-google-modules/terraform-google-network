---
# Playbook Name: ibp-migration-cpids.yml
# Description: Performs a volume snapshot migration of cpids to a new AWS Instance.
#  Stops cpids application and created volume snapshots of the source.
#  New EBS Volumes are created from the snapshots. The Volumes are attached to a target
#  instance, with no pre-existing volumes except for root. The profile data is
#  migrated from source to target instances. Finally, the systemd services, polkit security,
#  and lss files are copied over to complete migration process.
#
#  To migrate between two inventories, the old inventory must contain the word `_old` in its
#  filename.  Likewise, the new inventory must not contain the word `_old` in its filename.
#  To execute ansible, follow the examples provided below.
#
#  Using two different ansible inventories will cause certain hostvars to be squashed and
#  merged.  Because of this, a single playbook cannot do a complete migration.  This playbook
#  must be combined with the ibp-operations-update-hosts, ibp-operations-hardstart, and
#  ibp-post-provision playbooks to finish the migration.
#
# Dependencies:
#   - Ansible v2.9+
#   - AWS CLI v1.18+
#   - Jinja2 2.8+
#   - sudo capability or root privileges on target machine
#   - ibp ansible role
#   - New Instances and prepared ansible inventory files (see description)
#   - ibp-operations-update-hosts Playbook (Completes Host entry update after migration)
#   - ibp-operations-hardstart playbook (Used to start cpids after migration)
#   - IAM Permissions:
#     - ec2:DescribeInstances
#     - ec2:DescribeVolumes
#     - ec2:AttachVolume
#     - ec2:CreateVolume
#     - ec2:StopInstances (optional)
#     - ec2:StartInstances (optional)
#     - ec2:Describe* (ansible aws requires something in here to start/stop instances. like wtf)
#     - ec2:CreateSnapshot
#     - ec2:DeleteSnapshot (optional)
# Variables:
#   - play_saphostagent_source : (optional) Alternate source for saphostagent install binaries. Leave blank to use inventory value
#   - play_cpids_sid : (optional) Lowercase play_cpids_sid Admin for cpids. Defaults to n02adm
#
# Example:
#   Execution on remote systems
#     ansible-playbook ibp-migration-cpids.yml -i </PATH-TO/OLD-HOST-INVENTORY-FILE> -i </PATH-TO/NEW-HOST-INVENTORY-FILE> -k
#
# Example
#   Execution on remote systems
#     ansible-playbook ibp-migration-cpids.yml -k -i /tmp/hosts_old -i /tmp/hosts
#
# Example
#   Update the hostfiles on all servers after this playbook is finished to complete migration.
#     ansible-playbook ibp-operations-update-hosts.yml -k -i /tmp/hosts
#
# Example
#   Start cpids after migration is complete.
#     ansible-playbook ibp-operations-hardstart.yml -k -i /tmp/hosts -l cpids
# Authors: Jian Ouyang, Dexter Le
# Version: 2.9-000002
# Modified: 2022-03-04 - Created playbook based on webdispatcher migration
#           2024-11-13 - Ensure local files are copied over to complete migration process
#
# Comments: |
#   This playbook is designed to be used with the ibp-ansible-inventory-template.yml
#   Play Tags:
#     play0 always                                      : Creates cpids Inventory and Collects Metadata
#     play1 stop-cpids clone-ebs clone-profile          : Stop Source cpids Application
#     play2 clone-ebs clone-profile                     : Clone cpids Volumes
#     play3 clone-profile                               : Clone cpids Profile Data
#     play4 clone-local-files-cpids                     : Clone local files (systemd service, lss, and polkit)
#     playEND                                           : End of the playbook


#################
##### Play0 #####
#################
- name: "Play0: Create cpids Inventory"
  hosts: cpids
  gather_facts: true
  tags:
    - play0
    - always

  vars:
    nfs_package: 'nfs-utils'

  vars_prompt:
  - name: play_saphostagent_source
    prompt: "Alternate source for saphostagent install binaries. Leave blank to use inventory value"
    private: no
    default: ''

  - name: play_cpids_sid
    prompt: "Lowercase play_cpids_sid for cpids."
    private: no
    default: 'n01'

  tasks:
  - name: "check whether aws default region is defined"
    delegate_to: localhost
    run_once: true
    assert:
      that:
          - "lookup('env','AWS_DEFAULT_REGION')"
      fail_msg: define environment variable AWS_DEFAULT_REGION before applying this playbook

  - name: "Get ec2 metadata"
    ec2_metadata_facts:

  - name: "Clear any dynamically created groups"
    meta: refresh_inventory

  - name: "Add old hosts to source group"
    when: "'_old' in inventory_file"
    group_by:
      key: source_hosts

  - name: "Add new hosts to target group"
    when: "'_old' not in inventory_file"
    group_by:
      key: target_hosts

  - name: "Validate target and source groups only contain one host each"
    when:
      - groups.source_hosts|count != 1
      - groups.target_hosts|count != 1
    fail:
      msg: |
        Source contains {{ groups.source_hosts|count }}
        Target contains {{ groups.target_hosts|count }}


  - name: "Set Source and Target Instance IDs"
    set_fact:
      play_source_instance: "{{ hostvars[groups.source_hosts[0]].ansible_ec2_instance_id }}"
      play_target_instance: "{{ hostvars[groups.target_hosts[0]].ansible_ec2_instance_id }}"
      play_saphostagent_source: "{{ play_saphostagent_source|default(saphostagent_source,true) }}"
      play_cpids_sid: "{{ play_cpids_sid }}"

  - name: "Configure Red Hat Repositories from S3"
    include_role:
      name: repository-management
    vars:
      repo_enable: 'true'
      application_preset_selection: ['base','epel','hana']

  - name: "Ensure NFS is installed."
    become: true
    package: "name={{ nfs_package }} state=installed"

#################
##### Play1 #####
#################
- name: "Play1: Stop Source cpids Application"
  hosts: cpids:&source_hosts
  tags:
    - play1
    - stop-cpids
    - clone-ebs
    - clone-profile

  tasks:
  - name: "Stop cpids Application"
    include_role:
      name: ibp
      allow_duplicates: yes
      tasks_from: operations/cpids-softstop.yml


#################
##### Play2 #####
#################
- name: "Play2: Clone cpids Volumes"
  hosts: cpids
  gather_facts: true
  tags:
    - play2
    - clone-ebs
    - clone-profile

  tasks:
  - name: "Clone and Attach Volumes"
    include_role:
      name: ibp
      allow_duplicates: yes
      tasks_from: general/ebs-clone.yml
    vars:
      ebs_clone_source_instance: "{{ play_source_instance }}"
      ebs_clone_target_instance: "{{ play_target_instance }}"
      ebs_clone_region: "{{ ansible_ec2_placement_region }}"

  - name: "Make sure instances are up and responding"
    wait_for_connection:

  - name: "Clone fstab and Mount"
    include_role:
      name: ibp
      allow_duplicates: yes
      tasks_from: general/fstab-clone.yml
    vars:
      fstab_clone_mount_targets:
        - "/hana/backups"
        - "/hana/data"
        - "/hana/log"
        - "/hana/shared"
        - "/usr/sap"
        - "/staging"

#################
##### Play3 #####
#################
- name: "Play3: Clone cpids Profile Data"
  hosts: cpids
  tags:
    - play3
    - clone-profile

  vars:
    staging_location: '/staging/migrations'

  pre_tasks:
  - name: "Generate role dynamic variables"
    include_role:
      name: ibp
      allow_duplicates: yes
      tasks_from: general/variables-create.yml

  tasks:
  - name: "Create destination folder"
    when: "'source_hosts' in group_names"
    become: true
    file:
      path: "{{ staging_location }}/{{ play_source_instance }}"
      state: directory

  - name: "Tar cpids profile folders"
    when: "'source_hosts' in group_names"
    include_role:
      name: ibp
      allow_duplicates: yes
      tasks_from: general/folder-tar.yml
    vars:
      folder_tar_name: "{{ staging_location }}/{{ play_source_instance }}/cpids"
      folder_tar_paths:
      - "/home/sapadm"
      - "/var/lib/hdb"
      - "/etc/incron.d"

  - name: "Setup cpids Profile on Target"
    when: "'target_hosts' in group_names"
    include_role:
      name: ibp
      allow_duplicates: yes
      tasks_from: provisioning/cpids-rebuild-profile.yml
    vars:
      cpids_rebuild_profile_tars:
        - "{{ staging_location }}/{{ play_source_instance }}/cpids"
      cpids_rebuild_profile_saphostagent_source: "{{ play_saphostagent_source }}"
      cpids_rebuild_profile_hostname: "{{ ibp_hostname }}"
      cpids_rebuild_profile_sid: "{{ play_cpids_sid|lower }}"

  - name: "Cleanup cpids Migration Tars"
    when: "'target_hosts' in group_names"
    become: true
    file:
      path: "{{ staging_location }}/{{ play_source_instance }}/cpids"
      state: absent

#################
##### Play4 #####
#################
- name: "Play4: Initiate migrate operation"
  hosts: source_hosts:target_hosts:&cpids
  any_errors_fatal: yes
  gather_facts: false
  tags:
    - play4
    - clone-local-files-cpids

  tasks:

  - name: "Generate role dynamic variables"
    include_role:
      name: ibp
      allow_duplicates: yes
      tasks_from: general/variables-create.yml

  - name: Determine location of source host lss directory
    become: true
    when: "'source_hosts' in group_names"
    ansible.builtin.stat:
      path: "{{ lss_path }}"
    register: ibp_migration_cpids_lss_stat
    loop_control:
      loop_var: lss_path
    loop:
      - /usr/sap/lss
      - /lss

  - name: Set fact for source lss directories that exist
    when: "'source_hosts' in group_names"
    ansible.builtin.set_fact:
      ibp_migration_cpids_existing_lss_dirs: "{{ ibp_migration_cpids_lss_stat.results | selectattr('stat.exists') | map(attribute='lss_path') | list }}"

  - name: "Create TARs of CPIDS files"
    when: "'source_hosts' in group_names"
    ansible.builtin.include_role:
      name: ibp
      tasks_from: general/folder-tar.yml
    vars:
      folder_tar_name: '{{ file | basename | regex_replace("\.(.*)$", "") }}'
      folder_tar_paths: "{{ [file] }}"
    loop_control:
      loop_var: file
    loop: "{{ ibp_migration_cpids_existing_lss_dirs }}"

  - name: "Migrate local files to target host"
    ansible.builtin.include_role:
      name: ibp
      tasks_from: operations/migrate-local-gzip-files.yml
    vars:
      ibp_local_gzip_files: "{{ hostvars[groups.source_hosts[0]].ibp_migration_cpids_existing_lss_dirs }}"
      ibp_source_hostname: "{{ hostvars[groups.source_hosts[0]].inventory_hostname }}"
      ibp_target_hostname: "{{ hostvars[groups.target_hosts[0]].inventory_hostname }}"

  - name: Apply migration
    ansible.builtin.include_role:
      name: ibp
      tasks_from: operations/initiate-migration.yml
    vars:
      sid: "{{ play_cpids_sid }}"
      ibp_instances:
        - name: HDB
          number: "00"

  - name: Set package compat map
    set_fact:
      compat_package_map:
        RedHat8: compat-sap-c++-11.x86_64
        RedHat9: compat-sap-c++-13.x86_64

  - name: Get Specific compat package
    set_fact:
      compat_package: "{{ compat_package_map[ansible_distribution + ansible_distribution_major_version] }}"

  - name: Install required yum packages
    become: true
    ansible.builtin.yum:
      name: "{{ packages }}"
    vars:
      packages:
      - "{{ compat_package }}"
      - tuned-profiles-sap-hana.noarch
      - libatomic
      - libstdc++.so.6

  - name: Determine location of target lss directory
    become: true
    when: "'target_hosts' in group_names"
    ansible.builtin.stat:
      path: "{{ lss_symlink_path }}"
    register: ibp_migration_cpids_lss_stat
    loop_control:
      loop_var: lss_symlink_path
    loop:
      - "/usr/sap/lss/shared/{{ play_cpids_sid | upper }}/exe/libstdc++.so.6"
      - "/lss/shared/{{ play_cpids_sid | upper }}/exe/libstdc++.so.6"

  - name: Initialize symlink directories for /usr/sap/SYS
    when: "'target_hosts' in group_names"
    ansible.builtin.set_fact:
      ibp_migration_cpids_symlink_directories:
        - src: "/opt/rh/SAP/lib64/{{ compat_package | regex_replace('.x86_64', '.so') }}"
          dest: "/usr/sap/{{ play_cpids_sid | upper }}/SYS/exe/hdb/libstdc++.so.6"

  - name: Set fact on existing lss directories (at least one)
    when: "'target_hosts' in group_names"
    ansible.builtin.set_fact:
      ibp_migration_cpids_lss_symlink_directories:
        - src: "/opt/rh/SAP/lib64/{{ compat_package | regex_replace('.x86_64', '.so') }}"
          dest: "{{ lss_path }}"
    loop_control:
      loop_var: lss_path
    loop: "{{ ibp_migration_cpids_lss_stat.results | selectattr('stat.exists') | map(attribute='lss_symlink_path') | list }}"

  - name : "Create libstdc++.so.6 symlinks"
    when: "'target_hosts' in group_names"
    become: true
    ansible.builtin.file:
      src: "{{ symlink.src }}"
      dest: "{{ symlink.dest }}"
      state: link
      owner: sapadm
      group: sapsys
    loop_control:
      loop_var: symlink
    loop: "{{ ibp_migration_cpids_symlink_directories + ibp_migration_cpids_lss_symlink_directories | default([], true) }}"


###################
##### PlayEND #####
###################
- name: "PlayEND: End of playbook"
  hosts: all
  gather_facts: false
  become: false
  tags:
  - play-end
  - always
  - the-end

  tasks:
  - name: "This is the end"
    delegate_to: localhost
    run_once: true
    debug:
      msg: "Of the world as we know it"
...